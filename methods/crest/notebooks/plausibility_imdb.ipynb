{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c8e00-36a6-4d1a-8894-fd407d83e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e082c0-dcf4-4549-84b1-2ebaa3de5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac181bf9-a07a-4c3d-a108-e01b99147149",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ok = 0\n",
    "total_er = 0\n",
    "\n",
    "def find_index_sublist(v, u_pad):\n",
    "    global total_ok, total_er\n",
    "    m = u_pad.index(t5_tokenizer.eos_token_id)  \n",
    "    u = u_pad[1:m]\n",
    "    n = len(u)\n",
    "    for i in range(len(v)-n):\n",
    "        if v[i:i+n] == u:\n",
    "            total_ok += 1\n",
    "            return i, i+n\n",
    "    total_er += 1\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def convert_evidences_to_mask(x, e):\n",
    "    start_end_idxs = [find_index_sublist(x, e_) for e_ in e]\n",
    "    mask = [0] * len(x)\n",
    "    for a, b in start_end_idxs:\n",
    "        if a is not None and b is not None:\n",
    "            for j in range(a, b):\n",
    "                mask[j] = 1\n",
    "    return mask\n",
    "\n",
    "def get_gold_explanations_from_movies_dataset(ds_movies):\n",
    "    valid_idxs = []\n",
    "    inputs_ids = []\n",
    "    gold_explanations = []\n",
    "    for i, sample in enumerate(ds_movies):\n",
    "        if len(sample['evidences']) == 0:\n",
    "            continue\n",
    "        \n",
    "        x = t5_tokenizer(sample['review'], truncation=True, max_length=512)\n",
    "        e = t5_tokenizer(sample['evidences'], truncation=True, max_length=512)\n",
    "        \n",
    "        # z = convert_evidences_to_mask(sample['review'], sample['evidences'])\n",
    "        z = convert_evidences_to_mask(x['input_ids'], e['input_ids'])\n",
    "        \n",
    "        valid_idxs.append(i)\n",
    "        inputs_ids.append(x['input_ids'])\n",
    "        gold_explanations.append(z)\n",
    "        \n",
    "    return valid_idxs, inputs_ids, gold_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a828d-8c93-47fa-9909-5d13260d2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_word_level_data(gold_explanations, model_explanations):\n",
    "    \"\"\"\n",
    "    Ignore word level samples with full OK or full BAD tags\n",
    "    \"\"\"\n",
    "    valid_gold, valid_model = [], []\n",
    "    for gold_expl, model_expl in zip(gold_explanations, model_explanations):\n",
    "        if sum(gold_expl) == 0 or sum(gold_expl) == len(gold_expl):\n",
    "            continue\n",
    "        else:\n",
    "            valid_gold.append(gold_expl)\n",
    "            valid_model.append(model_expl)\n",
    "    return valid_gold, valid_model\n",
    "\n",
    "\n",
    "def compute_auc_score(gold_explanations, model_explanations):\n",
    "    res = 0\n",
    "    for i in range(len(gold_explanations)):\n",
    "        res += roc_auc_score(gold_explanations[i], model_explanations[i])\n",
    "    return res / len(gold_explanations)\n",
    "\n",
    "\n",
    "def compute_ap_score(gold_explanations, model_explanations):\n",
    "    res = 0\n",
    "    for i in range(len(gold_explanations)):\n",
    "        res += average_precision_score(gold_explanations[i], model_explanations[i])\n",
    "    return res / len(gold_explanations)\n",
    "\n",
    "\n",
    "def compute_rec_topk(gold_explanations, model_explanations):\n",
    "    res = 0\n",
    "    for i in range(len(gold_explanations)):\n",
    "        idxs = np.argsort(model_explanations[i])[::-1][:int(sum(gold_explanations[i]))]\n",
    "        res += len([idx for idx in idxs if gold_explanations[i][idx] == 1])/sum(gold_explanations[i])\n",
    "    return res / len(gold_explanations)\n",
    "\n",
    "\n",
    "def compute_precision_recall_fscore_support(gold_explanations, model_explanations, threshold=0.0):\n",
    "    res_p, res_r, res_f = 0, 0, 0\n",
    "    for i in range(len(gold_explanations)):\n",
    "        expl = 1 * (np.array(model_explanations[i]) > threshold)\n",
    "        p, r, f, _ = precision_recall_fscore_support(gold_explanations[i], expl, average='binary', zero_division=1)\n",
    "        res_p += p\n",
    "        res_r += r\n",
    "        res_f += f\n",
    "    return res_p / len(gold_explanations), res_r / len(gold_explanations), res_f / len(gold_explanations)\n",
    "    \n",
    "\n",
    "def evaluate_word_level(gold_explanations, model_explanations, verbose=True, threshold=0.0):\n",
    "    gold_explanations, model_explanations = validate_word_level_data(gold_explanations, model_explanations)\n",
    "    prec, rec, f1 = compute_precision_recall_fscore_support(gold_explanations, model_explanations, threshold=threshold)\n",
    "    auc_score = compute_auc_score(gold_explanations, model_explanations)\n",
    "    ap_score = compute_ap_score(gold_explanations, model_explanations)\n",
    "    rec_topk = compute_rec_topk(gold_explanations, model_explanations)\n",
    "    if verbose:\n",
    "        print('Prec: {:.4f}'.format(prec))\n",
    "        print('Rec: {:.4f}'.format(rec))\n",
    "        print('F1: {:.4f}'.format(f1))\n",
    "        print('AUC score: {:.4f}'.format(auc_score))\n",
    "        print('AP score: {:.4f}'.format(ap_score))\n",
    "        print('Recall at top-K: {:.4f}'.format(rec_topk))\n",
    "    return prec, rec, f1, auc_score, ap_score, rec_topk\n",
    "\n",
    "\n",
    "def aggregate_pieces(x, mask, reduction='first'):\n",
    "    \"\"\"\n",
    "    :param x: tensor of shape (seq_len) or (seq_len, hdim)\n",
    "    :param mask: bool tensor of shape (seq_len)\n",
    "    :param reduction: aggregation strategy (first, max, sum, mean)\n",
    "    :returns: <s> word_1 word_2 ... </s>\n",
    "    where word_i = aggregate(piece_i_1, piece_i_2, ...)\n",
    "    \"\"\"\n",
    "    # mark <s> and </s> as True\n",
    "    special_mask = mask.clone()\n",
    "    special_mask[0] = special_mask[-1] = True\n",
    "    if reduction == 'first':\n",
    "        return x[special_mask.bool()]\n",
    "    elif reduction == 'sum' or reduction == 'mean' or reduction == 'max':\n",
    "        idx = special_mask.long().cumsum(dim=-1) - 1\n",
    "        idx_unique_count = torch.bincount(idx)\n",
    "        num_unique = idx_unique_count.shape[-1]\n",
    "        if reduction == 'sum':\n",
    "            res = torch.zeros(num_unique, device=x.device, dtype=x.dtype).scatter_add(0, idx, x)\n",
    "        elif reduction == 'mean':\n",
    "            res = torch.zeros(num_unique, device=x.device, dtype=x.dtype).scatter_add(0, idx, x)\n",
    "            res /= idx_unique_count.float()\n",
    "        else:\n",
    "            res = torch.stack([x[idx == i].max() for i in range(num_unique)]).to(x.device)\n",
    "        return res.float()\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_piece_explanations(all_explanations, all_fp_masks, reduction):\n",
    "    all_pieces = []\n",
    "    for expl, fp_mask in zip(all_explanations, all_fp_masks):\n",
    "        # aggregate word pieces scores (use my old good torch function)\n",
    "        agg_expl = aggregate_pieces(torch.tensor(expl), torch.tensor(fp_mask), reduction)\n",
    "        # remove <s> and </s>\n",
    "        all_pieces.append(agg_expl.tolist()[1:-1])\n",
    "    return all_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34552cc-fc86-4d36-b2e4-9d54b4b153b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\n",
    "    'movie_rationales',\n",
    "    download_mode=datasets.DownloadMode.REUSE_CACHE_IF_EXISTS,\n",
    ")\n",
    "_, x, z_gold = get_gold_explanations_from_movies_dataset(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432cf401-6c93-4131-972e-f6240f38797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rationales/revised_imdb_test_sparsemap_30p.tsv', delimiter='\\t')\n",
    "\n",
    "z = df['z'].map(eval)\n",
    "fp_masks = [[not tk.startswith('‚ñÅ') for tk in t5_tokenizer.convert_ids_to_tokens(ids)] for ids in x]\n",
    "\n",
    "fp_masks_l = [t[:len(z[i])] for i,t in enumerate(fp_masks)]\n",
    "z_gold_l = [t[:len(z[i])] for i,t in enumerate(z_gold)]\n",
    "\n",
    "pred_expls = get_piece_explanations(z, fp_masks_l, reduction='mean')\n",
    "gold_expls = get_piece_explanations(z_gold_l, fp_masks_l, reduction='max')\n",
    "_ = evaluate_word_level(gold_expls, pred_expls, verbose=True, threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95b7ac-dca8-4c0a-ac0b-459d3d393fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
